{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3f296f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-07-29T22:41:34.234584Z",
     "iopub.status.busy": "2024-07-29T22:41:34.234268Z",
     "iopub.status.idle": "2024-07-29T22:41:34.933936Z",
     "shell.execute_reply": "2024-07-29T22:41:34.933004Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.709903,
     "end_time": "2024-07-29T22:41:34.936963",
     "exception": false,
     "start_time": "2024-07-29T22:41:34.227060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/model.safetensors.index.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/model-00003-of-00004.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/model-00001-of-00004.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/model-00004-of-00004.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/model-00002-of-00004.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant/generation_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/run-flz7seda.wandb\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/logs/debug.log\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/logs/debug-internal.log\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/files/wandb-summary.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/files/conda-environment.yaml\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/files/config.yaml\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/files/output.log\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/files/requirements.txt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/wandb/run-20240729_190934-flz7seda/files/wandb-metadata.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3500/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1500/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2000/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-3000/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-500/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5000/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-5174/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-2500/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4500/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-4000/rng_state.pth\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/adapter_model.safetensors\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/trainer_state.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/training_args.bin\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/adapter_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/README.md\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/tokenizer.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/tokenizer_config.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/scheduler.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/special_tokens_map.json\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/optimizer.pt\n",
      "/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2/checkpoint-1000/rng_state.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be3b9b",
   "metadata": {
    "papermill": {
     "duration": 0.005506,
     "end_time": "2024-07-29T22:41:34.948449",
     "exception": false,
     "start_time": "2024-07-29T22:41:34.942943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Tuned model merging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20231858",
   "metadata": {
    "papermill": {
     "duration": 0.005378,
     "end_time": "2024-07-29T22:41:34.959496",
     "exception": false,
     "start_time": "2024-07-29T22:41:34.954118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have already trained the version 2 of the model, and now it should be merged with the version 1 model to be saved and used in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116ceb60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:41:34.972382Z",
     "iopub.status.busy": "2024-07-29T22:41:34.971904Z",
     "iopub.status.idle": "2024-07-29T22:42:57.457633Z",
     "shell.execute_reply": "2024-07-29T22:42:57.456383Z"
    },
    "papermill": {
     "duration": 82.495015,
     "end_time": "2024-07-29T22:42:57.460078",
     "exception": false,
     "start_time": "2024-07-29T22:41:34.965063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U bitsandbytes\n",
    "%pip install -U transformers\n",
    "%pip install -U accelerate\n",
    "%pip install -U peft\n",
    "%pip install -U trl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354955ca",
   "metadata": {
    "papermill": {
     "duration": 0.005659,
     "end_time": "2024-07-29T22:42:57.471786",
     "exception": false,
     "start_time": "2024-07-29T22:42:57.466127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Logging in to Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c812b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:42:57.484596Z",
     "iopub.status.busy": "2024-07-29T22:42:57.484284Z",
     "iopub.status.idle": "2024-07-29T22:42:58.123288Z",
     "shell.execute_reply": "2024-07-29T22:42:58.122273Z"
    },
    "papermill": {
     "duration": 0.647903,
     "end_time": "2024-07-29T22:42:58.125341",
     "exception": false,
     "start_time": "2024-07-29T22:42:57.477438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "hf_token = user_secrets.get_secret(\"huggingface_token\")\n",
    "login(token = hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06590b5",
   "metadata": {
    "papermill": {
     "duration": 0.005774,
     "end_time": "2024-07-29T22:42:58.137264",
     "exception": false,
     "start_time": "2024-07-29T22:42:58.131490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating variables for base and new models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603f9b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:42:58.150206Z",
     "iopub.status.busy": "2024-07-29T22:42:58.149906Z",
     "iopub.status.idle": "2024-07-29T22:42:58.153874Z",
     "shell.execute_reply": "2024-07-29T22:42:58.153039Z"
    },
    "papermill": {
     "duration": 0.01259,
     "end_time": "2024-07-29T22:42:58.155698",
     "exception": false,
     "start_time": "2024-07-29T22:42:58.143108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = \"/kaggle/input/llama-3-8b-medical-assistant/transformers/default/1/llama-3-8b-medical-assistant\"\n",
    "new_model = \"/kaggle/input/llama-3-8b-medical-assistant-v2/transformers/default/1/llama-3-8b-medical-assistant-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6bf857",
   "metadata": {
    "papermill": {
     "duration": 0.005706,
     "end_time": "2024-07-29T22:42:58.167237",
     "exception": false,
     "start_time": "2024-07-29T22:42:58.161531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To merge the base model with the adapter we should load the tokenizer and base model using the transformers library. Then, we set up the chat format using the trl library. Finally, we load and merge the adapter to the base model using the PEFT library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b182bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:42:58.179945Z",
     "iopub.status.busy": "2024-07-29T22:42:58.179686Z",
     "iopub.status.idle": "2024-07-29T22:46:14.324418Z",
     "shell.execute_reply": "2024-07-29T22:46:14.323421Z"
    },
    "papermill": {
     "duration": 196.153748,
     "end_time": "2024-07-29T22:46:14.326768",
     "exception": false,
     "start_time": "2024-07-29T22:42:58.173020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 22:43:04.601773: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 22:43:04.601884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 22:43:04.707740: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a28f3043c724ccb9845381d7a70a76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "from trl import setup_chat_format\n",
    "\n",
    "# Reload tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        return_dict=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff22bcc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:46:14.341138Z",
     "iopub.status.busy": "2024-07-29T22:46:14.340586Z",
     "iopub.status.idle": "2024-07-29T22:46:14.344896Z",
     "shell.execute_reply": "2024-07-29T22:46:14.344052Z"
    },
    "papermill": {
     "duration": 0.013304,
     "end_time": "2024-07-29T22:46:14.346772",
     "exception": false,
     "start_time": "2024-07-29T22:46:14.333468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f6bc9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:46:14.360168Z",
     "iopub.status.busy": "2024-07-29T22:46:14.359917Z",
     "iopub.status.idle": "2024-07-29T22:46:17.146321Z",
     "shell.execute_reply": "2024-07-29T22:46:17.145553Z"
    },
    "papermill": {
     "duration": 2.795843,
     "end_time": "2024-07-29T22:46:17.148743",
     "exception": false,
     "start_time": "2024-07-29T22:46:14.352900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge adapter with base model\n",
    "base_model_reload, tokenizer = setup_chat_format(base_model_reload, tokenizer)\n",
    "model = PeftModel.from_pretrained(base_model_reload, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963a4439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:46:17.162474Z",
     "iopub.status.busy": "2024-07-29T22:46:17.162156Z",
     "iopub.status.idle": "2024-07-29T22:46:17.446033Z",
     "shell.execute_reply": "2024-07-29T22:46:17.445197Z"
    },
    "papermill": {
     "duration": 0.293416,
     "end_time": "2024-07-29T22:46:17.448563",
     "exception": false,
     "start_time": "2024-07-29T22:46:17.155147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a20bfe",
   "metadata": {
    "papermill": {
     "duration": 0.005975,
     "end_time": "2024-07-29T22:46:17.461260",
     "exception": false,
     "start_time": "2024-07-29T22:46:17.455285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Model Inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd1e5e",
   "metadata": {
    "papermill": {
     "duration": 0.00582,
     "end_time": "2024-07-29T22:46:17.473135",
     "exception": false,
     "start_time": "2024-07-29T22:46:17.467315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To verify if our model has been merged correctly, we perform a simple inference using pipeline from the transformers library. We convert the message using the chat template and then provide a prompt to the pipeline. The pipeline was initialized using the model, tokenizer, and task type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "571330ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:46:17.486807Z",
     "iopub.status.busy": "2024-07-29T22:46:17.486468Z",
     "iopub.status.idle": "2024-07-29T22:46:32.039188Z",
     "shell.execute_reply": "2024-07-29T22:46:32.038245Z"
    },
    "papermill": {
     "duration": 14.562045,
     "end_time": "2024-07-29T22:46:32.041384",
     "exception": false,
     "start_time": "2024-07-29T22:46:17.479339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '<|im_start|>user\\nHello doctor, I have bad acne. How do I get rid of it? What medicine should I take?<|im_end|>\\n<|im_start|>assistant\\nHello, you need to maintain strict facial hygiene at a minimum level. Wash your face daily four-five times. Avoid taking oily and processed foods. Take the required amounts of sleep i.e eight hour at normal. Use natural oils that contain ant bacterial activity to wipe it off your face every now and then. It should be less by time but don\\'t see hope until 3 months. And don\\'t pop its not going to resolve well and is worse by a doctor named \"Scarring\". Avoid irritents as creams or moisturizers to the face because the acne might spread out further away. Consult your specialist. Avoid touching your face when stressed this is bad practice by my many patients because this tends hair, lips etc tend to irritate those in that zone further in that space of area. Eat a well formulated natural balanced diet by an expert like you have to be very strong because good food will keep your health sound for life and a clear skin that follows that your health is very bad if one goes'}]\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Hello doctor, I have bad acne. How do I get rid of it? What medicine should I take?\"}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "outputs = pipe(prompt, max_new_tokens=200, do_sample=True, temperature=2.1, top_k=50, top_p=0.95)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d968c9",
   "metadata": {
    "papermill": {
     "duration": 0.006004,
     "end_time": "2024-07-29T22:46:32.053941",
     "exception": false,
     "start_time": "2024-07-29T22:46:32.047937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that the fine-tuned model is working as expected after being merged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d3e62",
   "metadata": {
    "papermill": {
     "duration": 0.005923,
     "end_time": "2024-07-29T22:46:32.066004",
     "exception": false,
     "start_time": "2024-07-29T22:46:32.060081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Saving and pushing the merged model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a3a9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:46:32.080447Z",
     "iopub.status.busy": "2024-07-29T22:46:32.079371Z",
     "iopub.status.idle": "2024-07-29T22:47:28.975916Z",
     "shell.execute_reply": "2024-07-29T22:47:28.975079Z"
    },
    "papermill": {
     "duration": 71.171703,
     "end_time": "2024-07-29T22:47:43.243916",
     "exception": false,
     "start_time": "2024-07-29T22:46:32.072213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama-3-8b-medical-assistant-v2/tokenizer_config.json',\n",
       " 'llama-3-8b-medical-assistant-v2/special_tokens_map.json',\n",
       " 'llama-3-8b-medical-assistant-v2/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"llama-3-8b-medical-assistant-v2\")\n",
    "tokenizer.save_pretrained(\"llama-3-8b-medical-assistant-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79b720f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T22:47:43.533324Z",
     "iopub.status.busy": "2024-07-29T22:47:43.532162Z",
     "iopub.status.idle": "2024-07-29T22:50:16.288614Z",
     "shell.execute_reply": "2024-07-29T22:50:16.287739Z"
    },
    "papermill": {
     "duration": 153.010005,
     "end_time": "2024-07-29T22:50:16.297939",
     "exception": false,
     "start_time": "2024-07-29T22:47:43.287934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c60c281f3fe410592c8d8e3e9b95fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/McSimoff/llama-3-8b-medical-assistant-v2/commit/79041f837093dc4c2cb74a602964fd72947e8016', commit_message='Upload tokenizer', commit_description='', oid='79041f837093dc4c2cb74a602964fd72947e8016', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"llama-3-8b-medical-assistant-v2\", use_temp_dir=False)\n",
    "tokenizer.push_to_hub(\"llama-3-8b-medical-assistant-v2\", use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4d75f",
   "metadata": {
    "papermill": {
     "duration": 0.006347,
     "end_time": "2024-07-29T22:50:16.311271",
     "exception": false,
     "start_time": "2024-07-29T22:50:16.304924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "modelId": 92078,
     "modelInstanceId": 67052,
     "sourceId": 79798,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 96246,
     "modelInstanceId": 71250,
     "sourceId": 84814,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 528.403042,
   "end_time": "2024-07-29T22:50:19.876993",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-29T22:41:31.473951",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00c86770e2bd4c3d93f2c546e347918b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18b1dfce56c9425a9a282f16964c5fb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a28f3043c724ccb9845381d7a70a76e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a02cd61b139943dfb63dcdffbf749668",
        "IPY_MODEL_4659ad24d0af4f328a09ed9eafb60759",
        "IPY_MODEL_9d71147b445e462a8a94fc82e01a72f4"
       ],
       "layout": "IPY_MODEL_50c6b9c91cea4f259346582a850a42e7"
      }
     },
     "2aae1bd713f8477d8150ce63806ebf08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2b4638f260214fbcbe09c7cc674168c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4356b8a172bf45548e8f26c3d34b816d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4659ad24d0af4f328a09ed9eafb60759": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_18b1dfce56c9425a9a282f16964c5fb4",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6e561c06f142453596d0d65a1503e285",
       "value": 4.0
      }
     },
     "4a64c02d64d545b0b10a81ac28f81b4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "50c6b9c91cea4f259346582a850a42e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "561ef03708a04990bc633a6e971c9aa8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bea603f24b1d43c1b7a65080ad643880",
       "placeholder": "​",
       "style": "IPY_MODEL_4356b8a172bf45548e8f26c3d34b816d",
       "value": " 5.17k/5.17k [00:00&lt;00:00, 473kB/s]"
      }
     },
     "58323b0c124d4d9d8ce0f738af03f4a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5ecd5d0052484b11b219889c39dcb22a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "636d94f127584d389cd61c892b7778e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_638715f7f55b40c39b54aac42553a41c",
       "placeholder": "​",
       "style": "IPY_MODEL_2aae1bd713f8477d8150ce63806ebf08",
       "value": "README.md: 100%"
      }
     },
     "638715f7f55b40c39b54aac42553a41c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e561c06f142453596d0d65a1503e285": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7386c503e64a49599cbcde247bc29158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5c586a030da42f7bce147cd301d37ad",
       "max": 5174.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a620d6ba8a1c460b95a69b69a18fdf90",
       "value": 5174.0
      }
     },
     "9c60c281f3fe410592c8d8e3e9b95fae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_636d94f127584d389cd61c892b7778e9",
        "IPY_MODEL_7386c503e64a49599cbcde247bc29158",
        "IPY_MODEL_561ef03708a04990bc633a6e971c9aa8"
       ],
       "layout": "IPY_MODEL_2b4638f260214fbcbe09c7cc674168c2"
      }
     },
     "9d71147b445e462a8a94fc82e01a72f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_00c86770e2bd4c3d93f2c546e347918b",
       "placeholder": "​",
       "style": "IPY_MODEL_58323b0c124d4d9d8ce0f738af03f4a0",
       "value": " 4/4 [02:58&lt;00:00, 38.55s/it]"
      }
     },
     "a02cd61b139943dfb63dcdffbf749668": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5ecd5d0052484b11b219889c39dcb22a",
       "placeholder": "​",
       "style": "IPY_MODEL_4a64c02d64d545b0b10a81ac28f81b4c",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "a620d6ba8a1c460b95a69b69a18fdf90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bea603f24b1d43c1b7a65080ad643880": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5c586a030da42f7bce147cd301d37ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
